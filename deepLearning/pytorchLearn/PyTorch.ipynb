{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MnistNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MnistNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = MnistNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "train = torchvision.datasets.CIFAR10(root='/home/tbxsx/Code/learnMachineLearning/data/cifar',train=True,transform=transform)\n",
    "test = torchvision.datasets.CIFAR10(root='/home/tbxsx/Code/learnMachineLearning/data/cifar',train=False,transform=transform)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " (0 ,0 ,.,.) = \n",
       "  -0.3020 -0.3020 -0.2941  ...  -0.1608 -0.1686 -0.1765\n",
       "  -0.2784 -0.2706 -0.2706  ...  -0.1686 -0.1765 -0.1843\n",
       "  -0.2549 -0.2549 -0.2549  ...  -0.1608 -0.1686 -0.1922\n",
       "            ...             ⋱             ...          \n",
       "   0.0353  0.2157 -0.1686  ...  -0.1451 -0.1765 -0.2471\n",
       "   0.0980  0.2235  0.1216  ...  -0.2471 -0.3412 -0.1608\n",
       "   0.0431  0.1294  0.1529  ...  -0.3490 -0.4510 -0.1608\n",
       " \n",
       " (0 ,1 ,.,.) = \n",
       "   0.0118  0.0118  0.0039  ...   0.1922  0.1843  0.1765\n",
       "   0.0510  0.0431  0.0353  ...   0.1843  0.1765  0.1608\n",
       "   0.0745  0.0667  0.0588  ...   0.1922  0.1843  0.1608\n",
       "            ...             ⋱             ...          \n",
       "   0.0431  0.1843 -0.1686  ...   0.0902  0.0353 -0.0745\n",
       "   0.2000  0.3255  0.1922  ...  -0.1216 -0.2000 -0.0039\n",
       "   0.1765  0.2863  0.3176  ...  -0.2784 -0.2941  0.0039\n",
       " \n",
       " (0 ,2 ,.,.) = \n",
       "   0.0353  0.0353  0.0118  ...   0.3569  0.3647  0.3569\n",
       "   0.1294  0.0980  0.0588  ...   0.3804  0.3804  0.3490\n",
       "   0.1922  0.1529  0.1137  ...   0.3804  0.3961  0.3490\n",
       "            ...             ⋱             ...          \n",
       "  -0.5059 -0.3961 -0.5137  ...  -0.1843 -0.2235 -0.4353\n",
       "  -0.3961 -0.3176 -0.3804  ...  -0.5216 -0.7020 -0.5608\n",
       "  -0.4275 -0.3255 -0.3020  ...  -0.7255 -0.9059 -0.5529\n",
       "      ⋮ \n",
       " \n",
       " (1 ,0 ,.,.) = \n",
       "   0.0353  0.0902  0.1216  ...   0.1216  0.1373  0.1608\n",
       "   0.0196  0.0745  0.1451  ...   0.0510  0.0588  0.1608\n",
       "   0.0431  0.0902  0.0980  ...   0.0588  0.0431  0.0667\n",
       "            ...             ⋱             ...          \n",
       "  -0.0431  0.0353  0.0745  ...  -0.0118 -0.2157  0.0118\n",
       "   0.0353  0.0275  0.0275  ...  -0.0510 -0.1843 -0.0275\n",
       "   0.1843  0.1686  0.1216  ...   0.0745  0.0353  0.0902\n",
       " \n",
       " (1 ,1 ,.,.) = \n",
       "   0.0980  0.1373  0.1529  ...   0.1608  0.0980  0.0039\n",
       "   0.0902  0.1373  0.1529  ...   0.1294  0.0824  0.0824\n",
       "   0.1216  0.1608  0.0824  ...   0.1373  0.1137  0.0431\n",
       "            ...             ⋱             ...          \n",
       "  -0.0275  0.0667  0.0824  ...  -0.1529 -0.2471 -0.0118\n",
       "   0.0118  0.0353  0.0196  ...  -0.0824 -0.1608 -0.0118\n",
       "   0.0275  0.0824  0.0588  ...   0.0510  0.0431  0.0902\n",
       " \n",
       " (1 ,2 ,.,.) = \n",
       "  -0.4980 -0.4980 -0.4745  ...  -0.5137 -0.4353 -0.2157\n",
       "  -0.5373 -0.4902 -0.4196  ...  -0.5059 -0.4196 -0.1059\n",
       "  -0.5216 -0.4588 -0.4275  ...  -0.4745 -0.3725 -0.1294\n",
       "            ...             ⋱             ...          \n",
       "  -0.5686 -0.4980 -0.5059  ...  -0.5922 -0.5843 -0.1765\n",
       "  -0.4039 -0.3333 -0.3647  ...  -0.4039 -0.3569 -0.1059\n",
       "  -0.1608 -0.0431 -0.0588  ...  -0.0824 -0.0275  0.0588\n",
       "      ⋮ \n",
       " \n",
       " (2 ,0 ,.,.) = \n",
       "  -0.4824 -0.4824 -0.4667  ...  -0.5451 -0.5765 -0.6157\n",
       "  -0.7647 -0.7333 -0.6706  ...  -0.4745 -0.4824 -0.4902\n",
       "  -0.8588 -0.8745 -0.8275  ...  -0.4667 -0.4745 -0.4824\n",
       "            ...             ⋱             ...          \n",
       "   0.8353  0.8667  0.8510  ...   0.3490  0.4588  0.5843\n",
       "   0.8275  0.8431  0.7882  ...   0.6078  0.6784  0.7961\n",
       "   0.8196  0.7961  0.7804  ...   0.7176  0.7098  0.7961\n",
       " \n",
       " (2 ,1 ,.,.) = \n",
       "  -0.3255 -0.3176 -0.3176  ...  -0.4510 -0.4745 -0.5137\n",
       "  -0.6784 -0.6471 -0.5922  ...  -0.3490 -0.3647 -0.3725\n",
       "  -0.8275 -0.8431 -0.8039  ...  -0.3333 -0.3412 -0.3490\n",
       "            ...             ⋱             ...          \n",
       "   0.6549  0.6863  0.6706  ...   0.1765  0.2549  0.3647\n",
       "   0.5843  0.6000  0.5451  ...   0.4824  0.5294  0.6314\n",
       "   0.5686  0.5451  0.5294  ...   0.6078  0.5922  0.6549\n",
       " \n",
       " (2 ,2 ,.,.) = \n",
       "  -0.1216 -0.1294 -0.0824  ...  -0.3255 -0.3569 -0.3961\n",
       "  -0.5529 -0.5373 -0.4275  ...  -0.2000 -0.2157 -0.2235\n",
       "  -0.7725 -0.7961 -0.7098  ...  -0.1686 -0.1765 -0.1843\n",
       "            ...             ⋱             ...          \n",
       "   0.3804  0.4118  0.4039  ...  -0.0196  0.0510  0.1529\n",
       "   0.4431  0.4588  0.4039  ...   0.2235  0.2627  0.3647\n",
       "   0.3882  0.3647  0.3490  ...   0.2314  0.2157  0.2784\n",
       "      ⋮ \n",
       " \n",
       " (3 ,0 ,.,.) = \n",
       "   0.7804  0.7725  0.7647  ...   0.7412  0.7412  0.7333\n",
       "   0.7255  0.7333  0.7333  ...   0.7098  0.7098  0.7176\n",
       "   0.7176  0.7098  0.7255  ...   0.6863  0.6863  0.7020\n",
       "            ...             ⋱             ...          \n",
       "   0.1608  0.1529  0.1608  ...   0.2235  0.2235  0.2392\n",
       "   0.1216  0.1373  0.1451  ...   0.2784  0.2784  0.3098\n",
       "   0.1294  0.1373  0.1608  ...   0.2549  0.2549  0.2706\n",
       " \n",
       " (3 ,1 ,.,.) = \n",
       "   0.7961  0.7882  0.7804  ...   0.7569  0.7569  0.7490\n",
       "   0.7333  0.7412  0.7412  ...   0.7176  0.7176  0.7255\n",
       "   0.7255  0.7176  0.7333  ...   0.6941  0.6941  0.7098\n",
       "            ...             ⋱             ...          \n",
       "   0.0667  0.0667  0.0745  ...   0.1216  0.1294  0.1451\n",
       "   0.0275  0.0431  0.0510  ...   0.1765  0.1765  0.2078\n",
       "   0.0275  0.0353  0.0588  ...   0.1529  0.1529  0.1765\n",
       " \n",
       " (3 ,2 ,.,.) = \n",
       "   0.9137  0.9059  0.9059  ...   0.8745  0.8745  0.8667\n",
       "   0.8745  0.8824  0.8745  ...   0.8588  0.8588  0.8588\n",
       "   0.8824  0.8745  0.8902  ...   0.8510  0.8510  0.8667\n",
       "            ...             ⋱             ...          \n",
       "   0.1373  0.1294  0.1373  ...   0.2392  0.2392  0.2549\n",
       "   0.1373  0.1529  0.1608  ...   0.3098  0.3098  0.3412\n",
       "   0.1608  0.1686  0.1922  ...   0.2784  0.2784  0.3020\n",
       " [torch.FloatTensor of size (4,3,32,32)], \n",
       "  2\n",
       "  7\n",
       "  0\n",
       "  0\n",
       " [torch.LongTensor of size (4,)]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(trainloader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  car  deer plane   cat\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFARNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFARNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/cuda/__init__.py:116: UserWarning: \n",
      "    Found GPU0 GeForce 940M which is of cuda capability 5.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    }
   ],
   "source": [
    "net = CIFARNet()\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0005, momentum=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:22: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.763\n",
      "[1,  4000] loss: 0.758\n",
      "[1,  6000] loss: 0.792\n",
      "[1,  8000] loss: 0.823\n",
      "[1, 10000] loss: 0.860\n",
      "[1, 12000] loss: 0.840\n",
      "[2,  2000] loss: 0.728\n",
      "[2,  4000] loss: 0.776\n",
      "[2,  6000] loss: 0.764\n",
      "[2,  8000] loss: 0.802\n",
      "[2, 10000] loss: 0.797\n",
      "[2, 12000] loss: 0.809\n",
      "[3,  2000] loss: 0.690\n",
      "[3,  4000] loss: 0.746\n",
      "[3,  6000] loss: 0.776\n",
      "[3,  8000] loss: 0.780\n",
      "[3, 10000] loss: 0.784\n",
      "[3, 12000] loss: 0.778\n",
      "[4,  2000] loss: 0.689\n",
      "[4,  4000] loss: 0.731\n",
      "[4,  6000] loss: 0.713\n",
      "[4,  8000] loss: 0.765\n",
      "[4, 10000] loss: 0.779\n",
      "[4, 12000] loss: 0.771\n",
      "[5,  2000] loss: 0.665\n",
      "[5,  4000] loss: 0.702\n",
      "[5,  6000] loss: 0.702\n",
      "[5,  8000] loss: 0.742\n",
      "[5, 10000] loss: 0.751\n",
      "[5, 12000] loss: 0.756\n",
      "[6,  2000] loss: 0.656\n",
      "[6,  4000] loss: 0.688\n",
      "[6,  6000] loss: 0.716\n",
      "[6,  8000] loss: 0.705\n",
      "[6, 10000] loss: 0.751\n",
      "[6, 12000] loss: 0.737\n",
      "[7,  2000] loss: 0.645\n",
      "[7,  4000] loss: 0.667\n",
      "[7,  6000] loss: 0.705\n",
      "[7,  8000] loss: 0.707\n",
      "[7, 10000] loss: 0.738\n",
      "[7, 12000] loss: 0.722\n",
      "[8,  2000] loss: 0.609\n",
      "[8,  4000] loss: 0.673\n",
      "[8,  6000] loss: 0.686\n",
      "[8,  8000] loss: 0.706\n",
      "[8, 10000] loss: 0.692\n",
      "[8, 12000] loss: 0.723\n",
      "[9,  2000] loss: 0.619\n",
      "[9,  4000] loss: 0.639\n",
      "[9,  6000] loss: 0.687\n",
      "[9,  8000] loss: 0.674\n",
      "[9, 10000] loss: 0.736\n",
      "[9, 12000] loss: 0.725\n",
      "[10,  2000] loss: 0.594\n",
      "[10,  4000] loss: 0.636\n",
      "[10,  6000] loss: 0.651\n",
      "[10,  8000] loss: 0.698\n",
      "[10, 10000] loss: 0.704\n",
      "[10, 12000] loss: 0.699\n",
      "[11,  2000] loss: 0.598\n",
      "[11,  4000] loss: 0.594\n",
      "[11,  6000] loss: 0.650\n",
      "[11,  8000] loss: 0.682\n",
      "[11, 10000] loss: 0.680\n",
      "[11, 12000] loss: 0.717\n",
      "[12,  2000] loss: 0.563\n",
      "[12,  4000] loss: 0.630\n",
      "[12,  6000] loss: 0.644\n",
      "[12,  8000] loss: 0.666\n",
      "[12, 10000] loss: 0.687\n",
      "[12, 12000] loss: 0.715\n",
      "[13,  2000] loss: 0.583\n",
      "[13,  4000] loss: 0.623\n",
      "[13,  6000] loss: 0.640\n",
      "[13,  8000] loss: 0.654\n",
      "[13, 10000] loss: 0.679\n",
      "[13, 12000] loss: 0.694\n",
      "[14,  2000] loss: 0.545\n",
      "[14,  4000] loss: 0.612\n",
      "[14,  6000] loss: 0.619\n",
      "[14,  8000] loss: 0.629\n",
      "[14, 10000] loss: 0.699\n",
      "[14, 12000] loss: 0.696\n",
      "[15,  2000] loss: 0.559\n",
      "[15,  4000] loss: 0.626\n",
      "[15,  6000] loss: 0.632\n",
      "[15,  8000] loss: 0.646\n",
      "[15, 10000] loss: 0.684\n",
      "[15, 12000] loss: 0.651\n",
      "[16,  2000] loss: 0.541\n",
      "[16,  4000] loss: 0.618\n",
      "[16,  6000] loss: 0.627\n",
      "[16,  8000] loss: 0.648\n",
      "[16, 10000] loss: 0.643\n",
      "[16, 12000] loss: 0.688\n",
      "[17,  2000] loss: 0.541\n",
      "[17,  4000] loss: 0.584\n",
      "[17,  6000] loss: 0.632\n",
      "[17,  8000] loss: 0.646\n",
      "[17, 10000] loss: 0.652\n",
      "[17, 12000] loss: 0.684\n",
      "[18,  2000] loss: 0.549\n",
      "[18,  4000] loss: 0.584\n",
      "[18,  6000] loss: 0.635\n",
      "[18,  8000] loss: 0.618\n",
      "[18, 10000] loss: 0.684\n",
      "[18, 12000] loss: 0.630\n",
      "[19,  2000] loss: 0.561\n",
      "[19,  4000] loss: 0.579\n",
      "[19,  6000] loss: 0.591\n",
      "[19,  8000] loss: 0.635\n",
      "[19, 10000] loss: 0.642\n",
      "[19, 12000] loss: 0.652\n",
      "[20,  2000] loss: 0.549\n",
      "[20,  4000] loss: 0.548\n",
      "[20,  6000] loss: 0.601\n",
      "[20,  8000] loss: 0.612\n",
      "[20, 10000] loss: 0.655\n",
      "[20, 12000] loss: 0.689\n",
      "[21,  2000] loss: 0.544\n",
      "[21,  4000] loss: 0.590\n",
      "[21,  6000] loss: 0.589\n",
      "[21,  8000] loss: 0.645\n",
      "[21, 10000] loss: 0.617\n",
      "[21, 12000] loss: 0.647\n",
      "[22,  2000] loss: 0.504\n",
      "[22,  4000] loss: 0.568\n",
      "[22,  6000] loss: 0.613\n",
      "[22,  8000] loss: 0.618\n",
      "[22, 10000] loss: 0.647\n",
      "[22, 12000] loss: 0.660\n",
      "[23,  2000] loss: 0.539\n",
      "[23,  4000] loss: 0.572\n",
      "[23,  6000] loss: 0.595\n",
      "[23,  8000] loss: 0.603\n",
      "[23, 10000] loss: 0.607\n",
      "[23, 12000] loss: 0.635\n",
      "[24,  2000] loss: 0.523\n",
      "[24,  4000] loss: 0.583\n",
      "[24,  6000] loss: 0.608\n",
      "[24,  8000] loss: 0.598\n",
      "[24, 10000] loss: 0.615\n",
      "[24, 12000] loss: 0.653\n",
      "[25,  2000] loss: 0.536\n",
      "[25,  4000] loss: 0.558\n",
      "[25,  6000] loss: 0.588\n",
      "[25,  8000] loss: 0.614\n",
      "[25, 10000] loss: 0.655\n",
      "[25, 12000] loss: 0.626\n",
      "[26,  2000] loss: 0.549\n",
      "[26,  4000] loss: 0.570\n",
      "[26,  6000] loss: 0.568\n",
      "[26,  8000] loss: 0.602\n",
      "[26, 10000] loss: 0.619\n",
      "[26, 12000] loss: 0.641\n",
      "[27,  2000] loss: 0.543\n",
      "[27,  4000] loss: 0.552\n",
      "[27,  6000] loss: 0.598\n",
      "[27,  8000] loss: 0.608\n",
      "[27, 10000] loss: 0.662\n",
      "[27, 12000] loss: 0.655\n",
      "[28,  2000] loss: 0.534\n",
      "[28,  4000] loss: 0.596\n",
      "[28,  6000] loss: 0.583\n",
      "[28,  8000] loss: 0.638\n",
      "[28, 10000] loss: 0.640\n",
      "[28, 12000] loss: 0.645\n",
      "[29,  2000] loss: 0.535\n",
      "[29,  4000] loss: 0.559\n",
      "[29,  6000] loss: 0.603\n",
      "[29,  8000] loss: 0.590\n",
      "[29, 10000] loss: 0.622\n",
      "[29, 12000] loss: 0.620\n",
      "[30,  2000] loss: 0.506\n",
      "[30,  4000] loss: 0.570\n",
      "[30,  6000] loss: 0.564\n",
      "[30,  8000] loss: 0.588\n",
      "[30, 10000] loss: 0.650\n",
      "[30, 12000] loss: 0.635\n",
      "[31,  2000] loss: 0.522\n",
      "[31,  4000] loss: 0.553\n",
      "[31,  6000] loss: 0.578\n",
      "[31,  8000] loss: 0.648\n",
      "[31, 10000] loss: 0.602\n",
      "[31, 12000] loss: 0.619\n",
      "[32,  2000] loss: 0.509\n",
      "[32,  4000] loss: 0.566\n",
      "[32,  6000] loss: 0.593\n",
      "[32,  8000] loss: 0.620\n",
      "[32, 10000] loss: 0.606\n",
      "[32, 12000] loss: 0.629\n",
      "[33,  2000] loss: 0.507\n",
      "[33,  4000] loss: 0.566\n",
      "[33,  6000] loss: 0.587\n",
      "[33,  8000] loss: 0.632\n",
      "[33, 10000] loss: 0.621\n",
      "[33, 12000] loss: 0.601\n",
      "[34,  2000] loss: 0.482\n",
      "[34,  4000] loss: 0.525\n",
      "[34,  6000] loss: 0.611\n",
      "[34,  8000] loss: 0.625\n",
      "[34, 10000] loss: 0.605\n",
      "[34, 12000] loss: 0.642\n",
      "[35,  2000] loss: 0.559\n",
      "[35,  4000] loss: 0.579\n",
      "[35,  6000] loss: 0.588\n",
      "[35,  8000] loss: 0.591\n",
      "[35, 10000] loss: 0.604\n",
      "[35, 12000] loss: 0.631\n",
      "[36,  2000] loss: 0.503\n",
      "[36,  4000] loss: 0.587\n",
      "[36,  6000] loss: 0.614\n",
      "[36,  8000] loss: 0.578\n",
      "[36, 10000] loss: 0.608\n",
      "[36, 12000] loss: 0.621\n",
      "[37,  2000] loss: 0.522\n",
      "[37,  4000] loss: 0.573\n",
      "[37,  6000] loss: 0.601\n",
      "[37,  8000] loss: 0.593\n",
      "[37, 10000] loss: 0.619\n",
      "[37, 12000] loss: 0.621\n",
      "[38,  2000] loss: 0.517\n",
      "[38,  4000] loss: 0.553\n",
      "[38,  6000] loss: 0.601\n",
      "[38,  8000] loss: 0.644\n",
      "[38, 10000] loss: 0.641\n",
      "[38, 12000] loss: 0.683\n",
      "[39,  2000] loss: 0.562\n",
      "[39,  4000] loss: 0.583\n",
      "[39,  6000] loss: 0.569\n",
      "[39,  8000] loss: 0.598\n",
      "[39, 10000] loss: 0.662\n",
      "[39, 12000] loss: 0.643\n",
      "[40,  2000] loss: 0.527\n",
      "[40,  4000] loss: 0.537\n",
      "[40,  6000] loss: 0.594\n",
      "[40,  8000] loss: 0.607\n",
      "[40, 10000] loss: 0.620\n",
      "[40, 12000] loss: 0.652\n",
      "[41,  2000] loss: 0.488\n",
      "[41,  4000] loss: 0.580\n",
      "[41,  6000] loss: 0.586\n",
      "[41,  8000] loss: 0.612\n",
      "[41, 10000] loss: 0.612\n",
      "[41, 12000] loss: 0.657\n",
      "[42,  2000] loss: 0.541\n",
      "[42,  4000] loss: 0.558\n",
      "[42,  6000] loss: 0.586\n",
      "[42,  8000] loss: 0.599\n",
      "[42, 10000] loss: 0.638\n",
      "[42, 12000] loss: 0.645\n",
      "[43,  2000] loss: 0.526\n",
      "[43,  4000] loss: 0.554\n",
      "[43,  6000] loss: 0.624\n",
      "[43,  8000] loss: 0.590\n",
      "[43, 10000] loss: 0.641\n",
      "[43, 12000] loss: 0.646\n",
      "[44,  2000] loss: 0.522\n",
      "[44,  4000] loss: 0.571\n",
      "[44,  6000] loss: 0.573\n",
      "[44,  8000] loss: 0.581\n",
      "[44, 10000] loss: 0.617\n",
      "[44, 12000] loss: 0.635\n",
      "[45,  2000] loss: 0.521\n",
      "[45,  4000] loss: 0.587\n",
      "[45,  6000] loss: 0.624\n",
      "[45,  8000] loss: 0.614\n",
      "[45, 10000] loss: 0.637\n",
      "[45, 12000] loss: 0.627\n",
      "[46,  2000] loss: 0.519\n",
      "[46,  4000] loss: 0.558\n",
      "[46,  6000] loss: 0.597\n",
      "[46,  8000] loss: 0.593\n",
      "[46, 10000] loss: 0.631\n",
      "[46, 12000] loss: 0.648\n",
      "[47,  2000] loss: 0.518\n",
      "[47,  4000] loss: 0.583\n",
      "[47,  6000] loss: 0.614\n",
      "[47,  8000] loss: 0.624\n",
      "[47, 10000] loss: 0.631\n",
      "[47, 12000] loss: 0.614\n",
      "[48,  2000] loss: 0.548\n",
      "[48,  4000] loss: 0.597\n",
      "[48,  6000] loss: 0.606\n",
      "[48,  8000] loss: 0.634\n",
      "[48, 10000] loss: 0.639\n",
      "[48, 12000] loss: 0.617\n",
      "[49,  2000] loss: 0.535\n",
      "[49,  4000] loss: 0.571\n",
      "[49,  6000] loss: 0.642\n",
      "[49,  8000] loss: 0.622\n",
      "[49, 10000] loss: 0.625\n",
      "[49, 12000] loss: 0.643\n",
      "[50,  2000] loss: 0.519\n",
      "[50,  4000] loss: 0.561\n",
      "[50,  6000] loss: 0.592\n",
      "[50,  8000] loss: 0.590\n",
      "[50, 10000] loss: 0.636\n",
      "[50, 12000] loss: 0.636\n",
      "[51,  2000] loss: 0.575\n",
      "[51,  4000] loss: 0.595\n",
      "[51,  6000] loss: 0.589\n",
      "[51,  8000] loss: 0.638\n",
      "[51, 10000] loss: 0.609\n",
      "[51, 12000] loss: 0.637\n",
      "[52,  2000] loss: 0.579\n",
      "[52,  4000] loss: 0.531\n",
      "[52,  6000] loss: 0.572\n",
      "[52,  8000] loss: 0.633\n",
      "[52, 10000] loss: 0.621\n",
      "[52, 12000] loss: 0.667\n",
      "[53,  2000] loss: 0.557\n",
      "[53,  4000] loss: 0.572\n",
      "[53,  6000] loss: 0.569\n",
      "[53,  8000] loss: 0.602\n",
      "[53, 10000] loss: 0.605\n",
      "[53, 12000] loss: 0.631\n",
      "[54,  2000] loss: 0.554\n",
      "[54,  4000] loss: 0.571\n",
      "[54,  6000] loss: 0.595\n",
      "[54,  8000] loss: 0.622\n",
      "[54, 10000] loss: 0.679\n",
      "[54, 12000] loss: 0.665\n",
      "[55,  2000] loss: 0.551\n",
      "[55,  4000] loss: 0.603\n",
      "[55,  6000] loss: 0.628\n",
      "[55,  8000] loss: 0.618\n",
      "[55, 10000] loss: 0.662\n",
      "[55, 12000] loss: 0.637\n",
      "[56,  2000] loss: 0.563\n",
      "[56,  4000] loss: 0.595\n",
      "[56,  6000] loss: 0.605\n",
      "[56,  8000] loss: 0.620\n",
      "[56, 10000] loss: 0.628\n",
      "[56, 12000] loss: 0.668\n",
      "[57,  2000] loss: 0.605\n",
      "[57,  4000] loss: 0.587\n",
      "[57,  6000] loss: 0.640\n",
      "[57,  8000] loss: 0.609\n",
      "[57, 10000] loss: 0.628\n",
      "[57, 12000] loss: 0.635\n",
      "[58,  2000] loss: 0.559\n",
      "[58,  4000] loss: 0.545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58,  6000] loss: 0.636\n",
      "[58,  8000] loss: 0.638\n",
      "[58, 10000] loss: 0.587\n",
      "[58, 12000] loss: 0.630\n",
      "[59,  2000] loss: 0.563\n",
      "[59,  4000] loss: 0.556\n",
      "[59,  6000] loss: 0.666\n",
      "[59,  8000] loss: 0.614\n",
      "[59, 10000] loss: 0.632\n",
      "[59, 12000] loss: 0.672\n",
      "[60,  2000] loss: 0.540\n",
      "[60,  4000] loss: 0.572\n",
      "[60,  6000] loss: 0.579\n",
      "[60,  8000] loss: 0.605\n",
      "[60, 10000] loss: 0.664\n",
      "[60, 12000] loss: 0.627\n",
      "[61,  2000] loss: 0.543\n",
      "[61,  4000] loss: 0.583\n",
      "[61,  6000] loss: 0.590\n",
      "[61,  8000] loss: 0.617\n",
      "[61, 10000] loss: 0.641\n",
      "[61, 12000] loss: 0.646\n",
      "[62,  2000] loss: 0.518\n",
      "[62,  4000] loss: 0.593\n",
      "[62,  6000] loss: 0.576\n",
      "[62,  8000] loss: 0.659\n",
      "[62, 10000] loss: 0.666\n",
      "[62, 12000] loss: 0.638\n",
      "[63,  2000] loss: 0.567\n",
      "[63,  4000] loss: 0.662\n",
      "[63,  6000] loss: 0.623\n",
      "[63,  8000] loss: 0.603\n",
      "[63, 10000] loss: 0.658\n",
      "[63, 12000] loss: 0.685\n",
      "[64,  2000] loss: 0.584\n",
      "[64,  4000] loss: 0.612\n",
      "[64,  6000] loss: 0.614\n",
      "[64,  8000] loss: 0.609\n",
      "[64, 10000] loss: 0.649\n",
      "[64, 12000] loss: 0.656\n",
      "[65,  2000] loss: 0.561\n",
      "[65,  4000] loss: 0.607\n",
      "[65,  6000] loss: 0.653\n",
      "[65,  8000] loss: 0.645\n",
      "[65, 10000] loss: 0.654\n",
      "[65, 12000] loss: 0.639\n",
      "[66,  2000] loss: 0.537\n",
      "[66,  4000] loss: 0.669\n",
      "[66,  6000] loss: 0.590\n",
      "[66,  8000] loss: 0.637\n",
      "[66, 10000] loss: 0.663\n",
      "[66, 12000] loss: 0.645\n",
      "[67,  2000] loss: 0.523\n",
      "[67,  4000] loss: 0.617\n",
      "[67,  6000] loss: 0.590\n",
      "[67,  8000] loss: 0.625\n",
      "[67, 10000] loss: 0.655\n",
      "[67, 12000] loss: 0.670\n",
      "[68,  2000] loss: 0.573\n",
      "[68,  4000] loss: 0.584\n",
      "[68,  6000] loss: 0.599\n",
      "[68,  8000] loss: 0.640\n",
      "[68, 10000] loss: 0.650\n",
      "[68, 12000] loss: 0.651\n",
      "[69,  2000] loss: 0.554\n",
      "[69,  4000] loss: 0.606\n",
      "[69,  6000] loss: 0.636\n",
      "[69,  8000] loss: 0.623\n",
      "[69, 10000] loss: 0.653\n",
      "[69, 12000] loss: 0.655\n",
      "[70,  2000] loss: 0.540\n",
      "[70,  4000] loss: 0.612\n",
      "[70,  6000] loss: 0.603\n",
      "[70,  8000] loss: 0.679\n",
      "[70, 10000] loss: 0.637\n",
      "[70, 12000] loss: 0.666\n",
      "[71,  2000] loss: 0.562\n",
      "[71,  4000] loss: 0.618\n",
      "[71,  6000] loss: 0.615\n",
      "[71,  8000] loss: 0.641\n",
      "[71, 10000] loss: 0.649\n",
      "[71, 12000] loss: 0.678\n",
      "[72,  2000] loss: 0.580\n",
      "[72,  4000] loss: 0.625\n",
      "[72,  6000] loss: 0.668\n",
      "[72,  8000] loss: 0.671\n",
      "[72, 10000] loss: 0.655\n",
      "[72, 12000] loss: 0.665\n",
      "[73,  2000] loss: 0.591\n",
      "[73,  4000] loss: 0.599\n",
      "[73,  6000] loss: 0.652\n",
      "[73,  8000] loss: 0.633\n",
      "[73, 10000] loss: 0.639\n",
      "[73, 12000] loss: 0.663\n",
      "[74,  2000] loss: 0.577\n",
      "[74,  4000] loss: 0.628\n",
      "[74,  6000] loss: 0.653\n",
      "[74,  8000] loss: 0.611\n",
      "[74, 10000] loss: 0.666\n",
      "[74, 12000] loss: 0.686\n",
      "[75,  2000] loss: 0.632\n",
      "[75,  4000] loss: 0.628\n",
      "[75,  6000] loss: 0.643\n",
      "[75,  8000] loss: 0.656\n",
      "[75, 10000] loss: 0.672\n",
      "[75, 12000] loss: 0.679\n",
      "[76,  2000] loss: 0.598\n",
      "[76,  4000] loss: 0.607\n",
      "[76,  6000] loss: 0.626\n",
      "[76,  8000] loss: 0.667\n",
      "[76, 10000] loss: 0.665\n",
      "[76, 12000] loss: 0.663\n",
      "[77,  2000] loss: 0.565\n",
      "[77,  4000] loss: 0.589\n",
      "[77,  6000] loss: 0.679\n",
      "[77,  8000] loss: 0.652\n",
      "[77, 10000] loss: 0.648\n",
      "[77, 12000] loss: 0.660\n",
      "[78,  2000] loss: 0.622\n",
      "[78,  4000] loss: 0.616\n",
      "[78,  6000] loss: 0.643\n",
      "[78,  8000] loss: 0.626\n",
      "[78, 10000] loss: 0.673\n",
      "[78, 12000] loss: 0.685\n",
      "[79,  2000] loss: 0.588\n",
      "[79,  4000] loss: 0.639\n",
      "[79,  6000] loss: 0.676\n",
      "[79,  8000] loss: 0.668\n",
      "[79, 10000] loss: 0.717\n",
      "[79, 12000] loss: 0.676\n",
      "[80,  2000] loss: 0.571\n",
      "[80,  4000] loss: 0.626\n",
      "[80,  6000] loss: 0.655\n",
      "[80,  8000] loss: 0.668\n",
      "[80, 10000] loss: 0.674\n",
      "[80, 12000] loss: 0.694\n",
      "[81,  2000] loss: 0.592\n",
      "[81,  4000] loss: 0.643\n",
      "[81,  6000] loss: 0.637\n",
      "[81,  8000] loss: 0.589\n",
      "[81, 10000] loss: 0.657\n",
      "[81, 12000] loss: 0.684\n",
      "[82,  2000] loss: 0.593\n",
      "[82,  4000] loss: 0.648\n",
      "[82,  6000] loss: 0.642\n",
      "[82,  8000] loss: 0.696\n",
      "[82, 10000] loss: 0.683\n",
      "[82, 12000] loss: 0.664\n",
      "[83,  2000] loss: 0.573\n",
      "[83,  4000] loss: 0.605\n",
      "[83,  6000] loss: 0.646\n",
      "[83,  8000] loss: 0.671\n",
      "[83, 10000] loss: 0.695\n",
      "[83, 12000] loss: 0.698\n",
      "[84,  2000] loss: 0.607\n",
      "[84,  4000] loss: 0.590\n",
      "[84,  6000] loss: 0.661\n",
      "[84,  8000] loss: 0.684\n",
      "[84, 10000] loss: 0.698\n",
      "[84, 12000] loss: 0.703\n",
      "[85,  2000] loss: 0.625\n",
      "[85,  4000] loss: 0.664\n",
      "[85,  6000] loss: 0.638\n",
      "[85,  8000] loss: 0.645\n",
      "[85, 10000] loss: 0.703\n",
      "[85, 12000] loss: 0.694\n",
      "[86,  2000] loss: 0.612\n",
      "[86,  4000] loss: 0.624\n",
      "[86,  6000] loss: 0.675\n",
      "[86,  8000] loss: 0.624\n",
      "[86, 10000] loss: 0.688\n",
      "[86, 12000] loss: 0.673\n",
      "[87,  2000] loss: 0.563\n",
      "[87,  4000] loss: 0.636\n",
      "[87,  6000] loss: 0.681\n",
      "[87,  8000] loss: 0.669\n",
      "[87, 10000] loss: 0.675\n",
      "[87, 12000] loss: 0.720\n",
      "[88,  2000] loss: 0.607\n",
      "[88,  4000] loss: 0.632\n",
      "[88,  6000] loss: 0.674\n",
      "[88,  8000] loss: 0.702\n",
      "[88, 10000] loss: 0.666\n",
      "[88, 12000] loss: 0.693\n",
      "[89,  2000] loss: 0.654\n",
      "[89,  4000] loss: 0.635\n",
      "[89,  6000] loss: 0.650\n",
      "[89,  8000] loss: 0.714\n",
      "[89, 10000] loss: 0.717\n",
      "[89, 12000] loss: 0.714\n",
      "[90,  2000] loss: 0.644\n",
      "[90,  4000] loss: 0.647\n",
      "[90,  6000] loss: 0.635\n",
      "[90,  8000] loss: 0.684\n",
      "[90, 10000] loss: 0.659\n",
      "[90, 12000] loss: 0.717\n",
      "[91,  2000] loss: 0.577\n",
      "[91,  4000] loss: 0.628\n",
      "[91,  6000] loss: 0.639\n",
      "[91,  8000] loss: 0.736\n",
      "[91, 10000] loss: 0.753\n",
      "[91, 12000] loss: 0.744\n",
      "[92,  2000] loss: 0.602\n",
      "[92,  4000] loss: 0.674\n",
      "[92,  6000] loss: 0.681\n",
      "[92,  8000] loss: 0.647\n",
      "[92, 10000] loss: 0.645\n",
      "[92, 12000] loss: 0.692\n",
      "[93,  2000] loss: 0.608\n",
      "[93,  4000] loss: 0.623\n",
      "[93,  6000] loss: 0.670\n",
      "[93,  8000] loss: 0.675\n",
      "[93, 10000] loss: 0.682\n",
      "[93, 12000] loss: 0.724\n",
      "[94,  2000] loss: 0.619\n",
      "[94,  4000] loss: 0.689\n",
      "[94,  6000] loss: 0.686\n",
      "[94,  8000] loss: 0.713\n",
      "[94, 10000] loss: 0.672\n",
      "[94, 12000] loss: 0.656\n",
      "[95,  2000] loss: 0.582\n",
      "[95,  4000] loss: 0.614\n",
      "[95,  6000] loss: 0.646\n",
      "[95,  8000] loss: 0.718\n",
      "[95, 10000] loss: 0.737\n",
      "[95, 12000] loss: 0.690\n",
      "[96,  2000] loss: 0.624\n",
      "[96,  4000] loss: 0.647\n",
      "[96,  6000] loss: 0.662\n",
      "[96,  8000] loss: 0.667\n",
      "[96, 10000] loss: 0.718\n",
      "[96, 12000] loss: 0.734\n",
      "[97,  2000] loss: 0.586\n",
      "[97,  4000] loss: 0.648\n",
      "[97,  6000] loss: 0.660\n",
      "[97,  8000] loss: 0.740\n",
      "[97, 10000] loss: 0.732\n",
      "[97, 12000] loss: 0.704\n",
      "[98,  2000] loss: 0.630\n",
      "[98,  4000] loss: 0.691\n",
      "[98,  6000] loss: 0.721\n",
      "[98,  8000] loss: 0.728\n",
      "[98, 10000] loss: 0.762\n",
      "[98, 12000] loss: 0.664\n",
      "[99,  2000] loss: 0.591\n",
      "[99,  4000] loss: 0.651\n",
      "[99,  6000] loss: 0.651\n",
      "[99,  8000] loss: 0.700\n",
      "[99, 10000] loss: 0.774\n",
      "[99, 12000] loss: 0.733\n",
      "[100,  2000] loss: 0.638\n",
      "[100,  4000] loss: 0.626\n",
      "[100,  6000] loss: 0.701\n",
      "[100,  8000] loss: 0.716\n",
      "[100, 10000] loss: 0.722\n",
      "[100, 12000] loss: 0.765\n",
      "Finished Training\n",
      "Total Time: \n",
      "3971.529654979706\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "#         inputs, labels = Variable(inputs), Variable(labels)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "print(\"Total Time: \")\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:   frog   car  deer   car\n",
      "Predicted:   frog truck  deer truck\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fecfe32fb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "outputs = net(Variable(images.cuda()))\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5593\n",
      "10000\n",
      "Accuracy of the network on the 10000 test images: 55 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images.cuda()))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.cuda().size(0)\n",
    "    temp = (int)((predicted == labels.cuda()).sum())\n",
    "    correct += temp\n",
    "print(correct)\n",
    "print(total)\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = data\n",
    "outputs = net(Variable(images.cuda()))\n",
    "_, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 5\n",
       " 9\n",
       " 3\n",
       " 4\n",
       "[torch.cuda.LongTensor of size (4,) (GPU 0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 4\n",
       " 1\n",
       " 6\n",
       " 1\n",
       "[torch.LongTensor of size (4,)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (predicted == labels).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
